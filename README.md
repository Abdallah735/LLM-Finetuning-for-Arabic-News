# LLM-Finetuning-for-Arabic-News
 Fine-tuning a Large Language Model (LLM) to extract structured information and provide accurate translation for Arabic news articles using knowledge distillation and LLaMA Factory.

This project presents a fine-tuned Large Language Model (LLM) tailored to Arabic news articles. It performs two key tasks:
Structured Information Extraction â€” Converts unstructured Arabic news into a structured JSON format with title, summary, keywords, category, and named entities.
Translation to English â€” Translates the full news content and headline into fluent English.
We fine-tuned the Qwen2.5-1.5B-Instruct model using the LLaMA-Factory framework, leveraging a high-quality distilled dataset generated via OpenAI APIs.


## Project Structure
# datasets/
  Contains all data used in the fine-tuning process:
  news-sample.jsonl: Unlabeled Arabic news data.
  sft.jsonl: Supervised dataset distilled via OpenAI API.
  llamafactory-finetune-data/
       train.json: Training split for SFT.
       val.json: Validation split.

# models/
  Contains training artifacts:
  checkpoint-*: Saved checkpoints during fine-tuning.
  adapter_model.safetensors: Final fine-tuned model adapter.
  wandb/: Evaluation curves and metrics generated via Weights & Biases.

# llm_finetuning.ipynb
Notebook with all training, evaluation, and inference steps.


## Example
# input = '''
Ø£Ù†Ù‡Ù‰ Ù…Ø³Ø¦ÙˆÙ„Ùˆ Ø§Ù„Ù†Ø§Ø¯Ù‰ Ø§Ù„Ø£Ù‡Ù„Ù‰ ÙƒÙ„ ØªÙØ§ØµÙŠÙ„ Ø¹Ù‚Ø¯ Ø£Ø­Ù…Ø¯ Ù…ØµØ·ÙÙ‰ Ø²ÙŠØ²ÙˆØŒ Ø¬Ù†Ø§Ø­ Ø§Ù„Ø²Ù…Ø§Ù„ÙƒØŒ Ø¨Ø­ÙŠØ« ÙŠÙ†Ø¶Ù… Ø§Ù„Ù„Ø§Ø¹Ø¨ Ù„Ù…Ø¯Ø© 4 Ø³Ù†ÙˆØ§Øª Ù‚Ø§Ø¯Ù…Ø© Ø¨Ø¯Ø¡Ø§ Ù…Ù† Ø§Ù„Ù…ÙˆØ³Ù… Ø§Ù„Ø¬Ø¯ÙŠØ¯ØŒ ÙÙ‰ ØµÙÙ‚Ø© Ø§Ù†ØªÙ‚Ø§Ù„ Ø­Ø± Ø¨Ø¹Ø¯ Ù†Ù‡Ø§ÙŠØ© Ø¹Ù‚Ø¯Ù‡ Ù…Ø¹ Ø§Ù„Ø²Ù…Ø§Ù„Ùƒ Ø¹Ù‚Ø¨ Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ù…ÙˆØ³Ù… Ø§Ù„Ø­Ø§Ù„Ù‰.
ÙˆÙˆØ¶Ø¹ Ø§Ù„Ø£Ù‡Ù„Ù‰ Ø²ÙŠØ²Ùˆ ÙÙ‰ Ø§Ù„ÙØ¦Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ Ø¨Ø­ÙŠØ« ÙŠØ­ØµÙ„ Ø¹Ù„Ù‰ 25 Ù…Ù„ÙŠÙˆÙ† Ø¬Ù†ÙŠÙ‡ Ø³Ù†ÙˆÙŠØ§ Ø¨Ø§Ù„Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ Ø¹Ù‚Ø¯ Ø¥Ø¹Ù„Ø§Ù†Ù‰ Ù…Ù‚Ø§Ø¨Ù„ 60 Ù…Ù„ÙŠÙˆÙ† Ø¬Ù†ÙŠÙ‡ØŒ Ø¨Ø®Ù„Ø§Ù 80 Ù…Ù„ÙŠÙˆÙ† Ø¬Ù†ÙŠÙ‡ Ø£Ø®Ø±Ù‰ Ø³ÙŠØ­ØµÙ„ Ø¹Ù„ÙŠÙ‡Ø§ Ø¯ÙØ¹Ø© ÙˆØ§Ø­Ø¯Ø© Ù…Ù† Ø®Ø§Ø±Ø¬ Ø§Ù„Ù†Ø§Ø¯Ù‰ Ø¹Ù†Ø¯ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù† Ø§Ù„Ø±Ø³Ù…Ù‰ Ø¹Ù† Ø§Ù„ØµÙÙ‚Ø©.
ÙˆÙŠÙ†ØªÙ‡Ù‰ Ø¹Ù‚Ø¯ Ø£Ø­Ù…Ø¯ Ø³ÙŠØ¯ Ø²ÙŠØ²Ùˆ Ù…Ø¹ Ø§Ù„Ø²Ù…Ø§Ù„Ùƒ Ø¨Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ù…ÙˆØ³Ù… Ø§Ù„Ø¬Ø§Ø±Ù‰ØŒ Ù…Ù…Ø§ ÙŠØ¬Ø¹Ù„ Ù„Ù‡ Ø§Ù„Ø­Ù‚ ÙÙ‰ Ø§Ù„ØªÙØ§ÙˆØ¶ Ù…Ø¹ Ø£Ù‰ Ù†Ø§Ø¯Ù ÙˆØ¥ØªÙ…Ø§Ù… Ø§Ù„Ø§ØªÙØ§Ù‚ Ù…Ø¹Ù‡ ÙˆØ§Ù„Ø§Ù†Ø¶Ù…Ø§Ù… Ù„Ù‡ Ø¹Ù‚Ø¨ Ù†Ù‡Ø§ÙŠØ© Ø¹Ù‚Ø¯Ù‡ Ø§Ù„Ø­Ø§Ù„ÙŠ Ø®Ù„Ø§Ù„ ÙŠÙˆÙ†ÙŠÙˆ Ø§Ù„Ù…Ù‚Ø¨Ù„.
ÙˆØ­ØµÙ„ Ø²ÙŠØ²Ùˆ Ø¹Ù„Ù‰ ØªØ£Ø´ÙŠØ±Ø© Ø§Ù„Ø³ÙØ± Ù„Ø£Ù…Ø±ÙŠÙƒØ§ Ø¨Ø§Ù„ÙØ¹Ù„ Ù„Ù„Ù…Ø´Ø§Ø±ÙƒØ© Ù…Ø¹ Ø§Ù„Ø£Ù‡Ù„Ù‰ ÙÙŠ Ù…ÙˆÙ†Ø¯ÙŠØ§Ù„ Ø§Ù„Ø£Ù†Ø¯ÙŠØ© Ø§Ù„ØµÙŠÙ Ø§Ù„Ù…Ù‚Ø¨Ù„.
ÙˆÙŠØ³ØªØ¹Ø¯ Ø§Ù„Ø£Ù‡Ù„Ù‰ Ù„Ù„Ù…Ø´Ø§Ø±ÙƒØ© ÙÙ‰ Ø¨Ø·ÙˆÙ„Ø© ÙƒØ£Ø³ Ø§Ù„Ø¹Ø§Ù„Ù… Ù„Ù„Ø£Ù†Ø¯ÙŠØ© Ø¨Ø´ÙƒÙ„Ù‡Ø§ Ø§Ù„Ø¬Ø¯ÙŠØ¯ ÙÙ‰ Ø§Ù„ÙˆÙ„Ø§ÙŠØ§Øª Ø§Ù„Ù…ØªØ­Ø¯Ø© Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠØ©ØŒ ÙˆØ§Ù„Ù…Ù‚Ø§Ù…Ø© Ø¨Ù…Ø´Ø§Ø±ÙƒØ© 32 Ù†Ø§Ø¯ÙŠÙ‹Ø§ Ù…Ù† Ø£ÙƒØ¨Ø± ÙØ±Ù‚ Ø§Ù„Ø¹Ø§Ù„Ù….
'''
# Output â€“ Task 1: Structured Info Extraction
  {
   "story_title": "Ø£Ø­Ù…Ø¯ Ù…ØµØ·ÙÙ‰ Ø²ÙŠØ²Ùˆ ÙŠÙ†Ø¶Ù… Ù„Ù„Ø§Ù‡Ù„Ù‰ Ù„Ù…Ø¯Ø© 4 Ø³Ù†ÙˆØ§Øª Ø¨Ø¹Ø¯ Ø¹ÙˆØ¯Ø© Ø§Ù„Ø²Ù…Ø§Ù„Ùƒ",
   "story_keywords": [
     "Ø£Ø­Ù…Ø¯ Ù…ØµØ·ÙÙ‰ Ø²ÙŠØ²Ùˆ",
     "Ø§Ù„Ø§Ù‡Ù„Ù‰",
     "Ø§Ù„Ø²Ù…Ø§Ù„Ùƒ",
     "ØµÙÙ‚Ø© Ø§Ù†ØªÙ‚Ø§Ù„ Ø­Ø±",
     "Ù…ÙˆÙ†Ø¯ÙŠØ§Ù„ Ø§Ù„Ø£Ù†Ø¯ÙŠØ©"
   ],
   "story_summary": [
     "Ø£Ø­Ù…Ø¯ Ù…ØµØ·ÙÙ‰ Ø²ÙŠØ²Ùˆ ÙŠÙ†Ø¶Ù… Ù„Ù„Ø§Ù‡Ù„Ù‰ Ù„Ù…Ø¯Ø© 4 Ø³Ù†ÙˆØ§Øª.",
     "Ø§Ù„ØµÙÙ‚Ø© ØªØªØ¶Ù…Ù† 25 Ù…Ù„ÙŠÙˆÙ† Ø¬Ù†ÙŠÙ‡ Ø³Ù†ÙˆÙŠØ© Ùˆ60 Ù…Ù„ÙŠÙˆÙ† Ø¬Ù†ÙŠÙ‡ Ø¥Ø¹Ù„Ø§Ù†ÙŠØ©.",
     "Ø²ÙŠØ²Ùˆ ÙŠØ­ØµÙ„ Ø¹Ù„Ù‰ 80 Ù…Ù„ÙŠÙˆÙ† Ø¬Ù†ÙŠÙ‡ Ø£Ø®Ø±Ù‰ Ø¨Ø¹Ø¯ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù† Ø§Ù„Ø±Ø³Ù…ÙŠ.",
     "Ø²ÙŠØ²Ùˆ Ø­ØµÙ„ Ø¹Ù„Ù‰ ØªØ£Ø´ÙŠØ±Ø© Ø§Ù„Ø³ÙØ± Ù„Ø£Ù…Ø±ÙŠÙƒØ§ Ù„Ù„Ù…Ø´Ø§Ø±ÙƒØ© ÙÙŠ ÙƒØ£Ø³ Ø§Ù„Ø¹Ø§Ù„Ù…."
   ],
   "story_category": "sports",
   "story_entities": [
     {"entity_value": "Ø£Ø­Ù…Ø¯ Ù…ØµØ·ÙÙ‰ Ø²ÙŠØ²Ùˆ", "entity_type": "person-male"},
     {"entity_value": "Ø§Ù„Ø§Ù‡Ù„Ù‰", "entity_type": "organization"},
     {"entity_value": "Ø§Ù„Ø²Ù…Ø§Ù„Ùƒ", "entity_type": "organization"},
     {"entity_value": "Ù…ÙˆÙ†Ø¯ÙŠØ§Ù„ Ø§Ù„Ø£Ù†Ø¯ÙŠØ©", "entity_type": "event"},
     {"entity_value": "ÙƒØ£Ø³ Ø§Ù„Ø¹Ø§Ù„Ù… Ù„Ù„Ø£Ù†Ø¯ÙŠØ©", "entity_type": "event"},
     {"entity_value": "Ø£Ù…Ø±ÙŠÙƒØ§", "entity_type": "location"}
   ]
 }

 # Output â€“ Task 2: English Translation
 {
  "translated_title": "Ahmed Samy Zizou's Contract with Al Ahli Ends After Four Years",
  "translated_content": "The officials of Al Ahli have finalized all details regarding Ahmed Samy Zizou's contract with Zamalek, who is a midfielder for the Cairo club, allowing him to join the team for four years starting from the new season. The deal was made after the expiration of his contract with Zamalek at the end of this season.
Al Ahli placed Zizou in the first category, which entitles him to earn 25 million pounds annually in addition to a sponsorship contract worth 60 million pounds, along with another 80 million pounds that he will receive immediately upon the official announcement of the deal outside the club.
Ahmed Seddiq Zizou's contract with Zamalek ends at the end of this season, giving him the right to negotiate with any club and finalize the agreement before the end of his current contract next June.
Zizou has already obtained a travel visa to America to participate with Al Ahli in the upcoming World Club Championship during the summer.
Al Ahli is preparing to compete in the new format of the Club World Cup in the United States, held with 32 clubs from the world's largest teams."
}


## Technologies Used
- LLaMA-Factory â€“ Efficient framework for instruction tuning.
- Weights & Biases (WandB) â€“ Experiment tracking and visualization.
- HuggingFace Transformers â€“ Model architecture and tokenizer support.
- OpenAI API â€“ Used for knowledge distillation to generate high-quality training labels.

## Results & Insights
Instruction tuning with distilled SFT data led to better factual consistency, structured coherence, and cleaner translation quality.
Final model performs significantly better than zero-shot LLM prompting on the same tasks.
The project validates the power of knowledge distillation and low-rank fine-tuning for building robust Arabic language tools.


ğŸ“Œ References
Qwen2.5-1.5B-Instruct: https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct
LLaMA-Factory: https://github.com/hiyouga/LLaMA-Factory
Weights & Biases: https://wandb.ai/
HuggingFace Transformers: https://huggingface.co/




 
 Ù‡
